# -*- coding: utf-8 -*-
"""Race_Face.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z3mLnbYk3lyXtLMw_37wZ8JKckC8c6o9
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import tensorflow_addons as tfa
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Model
from tensorflow.keras.losses import mean_squared_error, mean_absolute_error
import time
import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %pylab inline
import sys
import cv2
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.applications.vgg16 import preprocess_input
print(tf.__version__)

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()

drive = GoogleDrive(gauth)

fid = drive.ListFile({'q':"title='NM_cycleGAN.zip'"}).GetList()[0]['id']
f = drive.CreateFile({'id': fid})
f.GetContentFile('NM_cycleGAN.zip')

!unzip NM_cycleGAN.zip

PATH = '/content/NM_CycleGAN'

train_A_dir = os.path.join(PATH, 'Train_A')
train_B_dir = os.path.join(PATH, 'Train_B')
test_A_dir = os.path.join(PATH, 'Train_Test_A')
test_B_dir = os.path.join(PATH, 'Train_Test_B')

train_A = os.path.join(train_A_dir, 'Negroid')
train_B = os.path.join(train_B_dir, 'Mongoloid')
test_A = os.path.join(test_A_dir, "Test_Negroid")
test_B = os.path.join(test_B_dir, "Test_Mongoloid")

num_Negroid_tr = len(os.listdir(train_A))
num_Mongoloid_tr = len(os.listdir(train_B))
num_Caucasian_tr = len(os.listdir(test_A))
num_Caucasian_try = len(os.listdir(test_B))

print('total training Negroid images:', num_Negroid_tr)
print('total training Mongoloid images:', num_Mongoloid_tr)
print('total testing Negroid images:', num_Caucasian_tr)
print('total testing Mongoloid images:', num_Caucasian_try)

EPOCHS = 10

def load_images(folder):
    images = []
    for filename in os.listdir(folder):
        im = cv2.imread(os.path.join(folder,filename))
        if im is not None:
            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
            im = cv2.resize(im, (64, 64))
            im = tf.cast(im, tf.float32)
            im = np.expand_dims(im, axis=0)
            im = (im / 127.5) - 1
            images.append(im)
    train_images = np.asarray(images)
    return train_images

train_data_A = load_images(train_A +"/")

train_A = train_data_A.reshape(train_data_A.shape[0], 64, 64, 3)
print(train_A.shape)

train_data_B = load_images(train_B +"/")

train_B = train_data_B.reshape(train_data_B.shape[0], 64, 64, 3)
print(train_B.shape)

test_data_A = load_images(test_A +"/")

test_A = test_data_A.reshape(test_data_A.shape[0], 64, 64, 3)
print(test_A.shape)

test_data_B = load_images(test_B +"/")

test_B = test_data_B.reshape(test_data_B.shape[0], 64, 64, 3)
print(test_B.shape)

def create_dataset(image_array, BUFFER_SIZE = 1000, BATCH_SIZE = 1):
    image_data = tf.data.Dataset.from_tensor_slices(image_array).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
    return image_data

train_A = create_dataset(train_A)
train_B = create_dataset(train_B)
test_A = create_dataset(test_A)
test_B = create_dataset(test_B)

inpA = next(iter(train_A))
inpB = next(iter(train_B))

plt.subplot(121)
plt.title("Train Set A")
plt.imshow(inpA[0]*0.5 + 0.5)
plt.subplot(122)
plt.title("Train Set B")
plt.imshow(inpB[0]*0.5 + 0.5)

def downsample(filters, size=3, apply_instancenorm=True, decoding=False, encoding=False, apply_dropout_1=False, apply_dropout_2=False ):
    initializer = tf.random_normal_initializer(0., 0.02)

    result = tf.keras.Sequential()
    result.add(
      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',
                             kernel_initializer=initializer, use_bias=False))

    if apply_instancenorm:
        result.add(tfa.layers.InstanceNormalization())

    if decoding:
        result.add(tf.keras.layers.ELU())

    if encoding:
        result.add(tf.keras.layers.ReLU())

    if apply_dropout_1:
        result.add(tf.keras.layers.Dropout(0.2))

    if apply_dropout_2:
        result.add(tf.keras.layers.Dropout(0.1))

    
        


    return result

def upsample(filters, size=3, apply_dropout_1=False, apply_dropout_2=False):
    initializer = tf.random_normal_initializer(0., 0.02)

    result = tf.keras.Sequential()
    result.add(
    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,
                                    padding='same',
                                    kernel_initializer=initializer,
                                    use_bias=False))

    result.add(tfa.layers.InstanceNormalization())

    result.add(tf.keras.layers.ELU())

    if apply_dropout_1:
        result.add(tf.keras.layers.Dropout(0.2))
    if apply_dropout_2:
        result.add(tf.keras.layers.Dropout(0.1))

   

    return result

class ResnetIdentityBlock(tf.keras.Model):
    def __init__(self, kernel_size, filters):
        super(ResnetIdentityBlock, self).__init__(name='')
        filters1, filters2, filters3 = filters

        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1), padding="valid")
        self.bn2a = tfa.layers.InstanceNormalization()

        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')
        self.bn2b = tfa.layers.InstanceNormalization()

        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1), padding="valid")
        self.bn2c = tfa.layers.InstanceNormalization()

    def call(self, input_tensor, training=False):
        x = self.conv2a(input_tensor)
        x = self.bn2a(x, training=training)
        

        x = self.conv2b(x)
        x = self.bn2b(x, training=training)
        

        x = self.conv2c(x)
        x = self.bn2c(x, training=training)

        x += input_tensor
        return tf.nn.elu(x)

    
block1 = ResnetIdentityBlock(3, [512, 512, 512])
block2 = ResnetIdentityBlock(3, [512, 512, 512])
block3 = ResnetIdentityBlock(3, [512, 512, 512])
block4 = ResnetIdentityBlock(3, [512, 512, 512])


resnet = [block1, block2, block3, block4]

def Generator():
    down_stack = [
        downsample(64, 4, apply_instancenorm=False, decoding=True), 
        downsample(128, 4, decoding=True),
        downsample(256, 4, decoding=True), 
        downsample(512, 4, decoding=True) 
    ]

    up_stack = [
        upsample(256, 4),
        upsample(128, 4), 
        upsample(64, 4), 
    ]

    initializer = tf.random_normal_initializer(0., 0.02)
    last = tf.keras.layers.Conv2DTranspose(3, 4,
                                         strides=2,
                                         padding='same',
                                         kernel_initializer=initializer,
                                         activation='tanh') 


    inputs = tf.keras.layers.Input(shape=[64, 64, 3])
    x = inputs

    # Downsampling through the model
    skips = []
    for down in down_stack:
        x = down(x)
        skips.append(x)
        
    for block in resnet:
        x = block(x)

    skips = reversed(skips[:-1])

    # Upsampling and establishing the skip connections
    for up, skip in zip(up_stack, skips):
        concat = tf.keras.layers.Concatenate()
        x = up(x)
        x = concat([x, skip])

    x = last(x)

    return tf.keras.Model(inputs=inputs, outputs=x)

tf.keras.utils.plot_model(generator, 'generator.png', show_shapes=True)

generator = Generator()
gen_output = generator(inpA, training=False)
gen_output = (gen_output + 1) / 2 
plt.imshow(gen_output[0])
print(gen_output.shape,gen_output[0,...].numpy().max(), gen_output[0,...].numpy().min())

def Discriminator():
    inputs = tf.keras.layers.Input(shape=[None,None,3])
    x = inputs
    g_filter = 64
    
    down_stack = [
        downsample(g_filter, decoding=True, apply_instancenorm=False),
        downsample(g_filter * 2, decoding=True),
        downsample(g_filter * 4, decoding=True),
        downsample(g_filter * 8, decoding=True),
    ]
    
    for down in down_stack:
        x = down(x)


    
    
    last = tf.keras.layers.Conv2D(1, 4, strides=1, padding='same') # (bs, 30, 30, 1)
    
    x = last(x)

    return tf.keras.Model(inputs=inputs, outputs=x)

tf.keras.utils.plot_model(discriminator, 'discriminator.png', show_shapes=True)

discriminator = Discriminator()
dis_output = discriminator(inpA, training=False)
print(dis_output.shape)

discriminator_Mongoloid = Discriminator()
discriminator_Negroid = Discriminator()

generator_Negroid_to_Mongoloid = Generator()
generator_Mongoloid_to_Negroid = Generator()

loss_object = tf.keras.losses.MeanSquaredError()

@tf.function
def discriminator_loss(disc_real_output, disc_generated_output):
    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)
    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)
    total_disc_loss = 0.5 * (real_loss + generated_loss)
    return total_disc_loss

optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)

valid = np.ones((1, 4, 4, 1)).astype('float32')
fake = np.zeros((1, 4, 4, 1)).astype('float32')

@tf.function
def train_batch(imgs_A, imgs_B):
    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:
        Fake_Mongoloid = generator_Negroid_to_Mongoloid(imgs_A, training=True)
        Fake_Negroid = generator_Mongoloid_to_Negroid(imgs_B, training=True)
        

        logits_real_A = discriminator_Negroid(imgs_A, training=True)
        logits_fake_A = discriminator_Negroid(Fake_Negroid, training=True)
        dA_loss = discriminator_loss(logits_real_A, logits_fake_A)


        logits_real_B = discriminator_Mongoloid(imgs_B, training=True)
        logits_fake_B = discriminator_Mongoloid(Fake_Mongoloid, training=True)
        dB_loss = discriminator_loss(logits_real_B, logits_fake_B)
        
       
        
        d_loss = (dA_loss + dB_loss) / 2



        # Translate images back to original domain
        reconstr_Negroid = generator_Mongoloid_to_Negroid(Fake_Mongoloid, training=True)
        reconstr_Mongoloid = generator_Negroid_to_Mongoloid(Fake_Negroid, training=True)
        
        id_Negroid = generator_Mongoloid_to_Negroid(imgs_A, training=True)
        id_Mongoloid = generator_Negroid_to_Mongoloid(imgs_B, training=True)


        gen_Mongoloid_loss = 5 * tf.math.reduce_mean(mean_squared_error(logits_fake_A, valid))
        gen_Negroid_loss = 5 * tf.math.reduce_mean(mean_squared_error(logits_fake_B, valid))
        Mongo_reconstr_loss = 10 * tf.math.reduce_mean(mean_absolute_error(reconstr_Negroid, imgs_A))
        Negro_reconstr_loss = 10 * tf.math.reduce_mean(mean_absolute_error(reconstr_Mongoloid, imgs_B))
        Mongo_id_loss = 2 * tf.math.reduce_mean(mean_absolute_error(id_Negroid, imgs_A))
        Negro_id_loss = 2 * tf.math.reduce_mean(mean_absolute_error(id_Mongoloid, imgs_B))

        gA_loss = tf.math.reduce_sum([
               gen_Negroid_loss,
               Negro_reconstr_loss,
               Negro_id_loss,

        ])


        gB_loss = tf.math.reduce_sum([
               gen_Mongoloid_loss ,
               Mongo_reconstr_loss,
               Mongo_id_loss,

        ])

        gen_loss = tf.math.reduce_sum([
            gen_Mongoloid_loss,
            gen_Negroid_loss,
            Mongo_reconstr_loss,
            Negro_reconstr_loss,
            Mongo_id_loss,
            Negro_id_loss,
        ])

            
    gradients_of_d = d_tape.gradient(d_loss, discriminator_Negroid.trainable_variables + discriminator_Mongoloid.trainable_variables)
    discriminator_optimizer.apply_gradients(zip(gradients_of_d, discriminator_Negroid.trainable_variables + discriminator_Mongoloid.trainable_variables))

    gradients_of_generator = g_tape.gradient(gen_loss, generator_Negroid_to_Mongoloid.trainable_variables + generator_Mongoloid_to_Negroid.trainable_variables)
    optimizer.apply_gradients(zip(gradients_of_generator, generator_Negroid_to_Mongoloid.trainable_variables + generator_Mongoloid_to_Negroid.trainable_variables))
    
    return dA_loss, dB_loss, d_loss, gen_loss, gen_Mongoloid_loss, gen_Negroid_loss, Mongo_reconstr_loss, Negro_reconstr_loss, Mongo_id_loss,  Negro_id_loss, gA_loss, gB_loss

def train(trainA_, trainB_, epochs):
    for epoch in range(epochs):
        start = time.time()
        
        for batch_i, (imgs_A, imgs_B) in enumerate(zip(trainA_, trainB_)):
            dA_loss, dB_loss, d_loss, gen_loss, gen_Mongoloid_loss, gen_Negroid_loss, Mongo_reconstr_loss, Negro_reconstr_loss, Mongo_id_loss,  Negro_id_loss, gA_loss, gB_loss = train_batch(imgs_A, imgs_B)
            
            if batch_i % 15142 == 0:
                test_imgA = next(iter(test_A))
                test_imgB = next(iter(test_B))
                print ('Time taken for epoch {} batch index {} is {} seconds\n'.format(epoch, batch_i, time.time()-start))
                print("discriminator Negroid: ", dA_loss.numpy())
                print("discriminator Mongoloid: ", dB_loss.numpy())
                print("discriminator: ", d_loss.numpy())
                print("generator: {}\n".format(gen_loss))
                print("generator_negro_loss: {}".format(gen_Negroid_loss))
                print("Negro_reconstr_loss: {}".format(Negro_reconstr_loss))
                print("Negro_id_loss: {}".format(Negro_id_loss))
                print("Total_loss: {}\n".format(gA_loss))
                print("generator_mongo_loss: {}".format(gen_Mongoloid_loss))
                print("Mongo_reconstr_loss: {}".format(Mongo_reconstr_loss))
                print("Mongo_id_loss: {}".format(Mongo_id_loss))
                print("Total_loss: {}\n".format(gB_loss))
                

                fig, axs = plt.subplots(2, 4, figsize=(30, 30), sharey=True, sharex=True)
                gen_outputA = generator_Negroid_to_Mongoloid(test_imgA, training=False)
                gen_id_A = generator_Mongoloid_to_Negroid(test_imgA, training=False)
                gen_reconstr_A = generator_Mongoloid_to_Negroid(gen_outputA, training=False)

                gen_outputB = generator_Mongoloid_to_Negroid(test_imgB, training=False)
                gen_id_B = generator_Negroid_to_Mongoloid(test_imgB, training=False)
                gen_reconstr_B = generator_Negroid_to_Mongoloid(gen_outputB, training=False)



                axs[0,0].imshow(test_imgA[0]*0.5 + 0.5)
                axs[0,0].set_title("Input", size = 20)
                axs[0,1].imshow(gen_outputA[0]*0.5 + 0.5)
                axs[0,1].set_title("Generator Negroid_to_Mongoloid", size = 20)
                axs[0,2].imshow(gen_reconstr_A[0]*0.5 + 0.5)
                axs[0,2].set_title("Reconstr_Negroid", size = 20)
                axs[0,3].imshow(gen_id_A[0]*0.5 + 0.5)
                axs[0,3].set_title("Identity Negroid", size = 20)


                axs[1,0].imshow(test_imgB[0]*0.5 + 0.5)
                axs[1,0].set_title("Input", size = 20)
                axs[1,1].imshow(gen_outputB[0]*0.5 + 0.5)
                axs[1,1].set_title("Generator Mongoloid_to_Negroid", size = 20)
                axs[1,2].imshow(gen_reconstr_B[0]*0.5 + 0.5)
                axs[1,2].set_title("Reconstr_Mongoloid", size = 20)
                axs[1,3].imshow(gen_id_B[0]*0.5 + 0.5)
                axs[1,3].set_title("Identity Mongoloid", size = 20)

                

                
                plt.show()

train(train_A, train_B, 15)